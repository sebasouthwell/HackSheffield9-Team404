{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_databricks import ChatDatabricks\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.prompts import HumanMessagePromptTemplate, ChatPromptTemplate\n",
    "from langchain_core.prompts.image import ImagePromptTemplate\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import base64\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Set os environment variables to dotenv file\n",
    "os.environ[\"DATABRICKS_TOKEN\"] = os.getenv(\"DATABRICKS_TOKEN\")\n",
    "os.environ[\"DATABRICKS_HOST\"] = os.getenv(\"DATABRICKS_HOST\")\n",
    "\n",
    "model = ChatDatabricks(\n",
    "        endpoint=\"databricks-meta-llama-3-1-70b-instruct\",\n",
    "        temperature=0.1,\n",
    "        max_tokens=250,\n",
    "   )\n",
    "\n",
    "\n",
    "prompt_template = HumanMessagePromptTemplate.from_template(\n",
    "    [{\"type\": \"text\", \"text\": \"Describe this weather type\"},\n",
    "     {\"type\": \"text\", \"text\": \"{weather_type}\"}]\n",
    ")\n",
    "\n",
    "describe_template = ChatPromptTemplate.from_messages([prompt_template])\n",
    "\n",
    "model_chain = describe_template | model\n",
    "\n",
    "response = model_chain.invoke({\"weather_type\": \"Sunny\"})\n",
    "\n",
    "print(response)\n",
    "\n",
    "# Function to encode a local image into data URL \n",
    "# def local_image_to_data_url(image_path):\n",
    "#     # Read and encode the image file\n",
    "#     with open(image_path, \"rb\") as image_file:\n",
    "#         base64_encoded_data = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "#     # Construct the data URL\n",
    "#     return f\"data:{'image/jpg'};base64,{base64_encoded_data}\"\n",
    "\n",
    "\n",
    "# prompt_template =  HumanMessagePromptTemplate.from_template(\n",
    "#             template=[\n",
    "#                 {\"type\": \"text\", \"text\": \"Summarize this image\"},\n",
    "#                 {\n",
    "#                     \"type\": \"image_url\",\n",
    "#                     \"image_url\": \"{encoded_image_url}\",\n",
    "#                 },\n",
    "#             ]\n",
    "#         )\n",
    "\n",
    "# summarize_image_prompt = ChatPromptTemplate.from_messages([prompt_template])\n",
    "\n",
    "# gpt4_image_chain = summarize_image_prompt | model \n",
    "\n",
    "# img_file = \"temp_image.jpg\"\n",
    "# image_encoded = local_image_to_data_url(img_file)\n",
    "\n",
    "\n",
    "# response = gpt4_image_chain.invoke({\"encoded_image_url\":image_encoded})\n",
    "# print(template_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img_file = \"temp_image.jpg\"\n",
    "image_encoded = local_image_to_data_url(img_file)\n",
    "\n",
    "response = gpt4_image_chain.invoke(input={\"encoded_image_url\":image_encoded})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
